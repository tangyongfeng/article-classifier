---
title: 扩展性测试总结
updated: 2013-04-18 18:14:33Z
created: 2013-04-17 15:03:36Z
---

机器结构图，|为逻辑分区，||为整机单位
|1|2|3|cf||4|5|6cf||7|8|9|
之前的启动顺序是1,2,3,4,5,6，启动到2的时候系统的扩展性大幅降低，判断应该是lpr对内存或者cache的影响，后来调整启动顺序，改为1,4,7,2,5,8,3,6,9 ，现象消失，说明之前的判断是正确的。
虽然到2的时候系统性能降低，但是按照这个情况的记录来看，其实到了9个节点的时候和现在的情况依然相近，所以只是阶段性的影响而已。在后来更复杂的表中，发现争抢主要实在lpr共用的情况下，如果是独立的机器应该没有类似的问题。尤其是6到9节点之间的过渡数据来看，是很平滑的。
50%交叉的数据表现最好，两个原因：1、有些我们没有控制好的东西。2、不管交叉多少，其实对系统的影响不是那么大。
case 6中login 和cancel的比率越多，线性度越差的原因是。case6和case5的cpu使用率不同，case6中使用70%的cpu使用率，后来的测试都是用50%的cpu使用率。实际上造成瓶颈的是io，因为io的速度慢，所以cpu都是在等待，而提高io的性能会减少线性度的降低，一方面是提高磁盘数量，另外一方面更重要的是增加CU的数目。
case8比case5好的原因：case8的login很多，也有对应的logout，能够清除对应的冗余数据。所以在真实运营过程中，很关键的，也需要定时清理数据。

case 8:  5%register 5%login 90bet 71%read  29%write 第一个图表是以交易笔数为单位，第二个图是按照节点数，share0 的话，扩展系数到9.66666，第三个表节点的扩展系数。

登录对系统的影响最大，一方面要建立新的索引，另外一方面又要删掉如果已经存在的索引。那是否在另外的机器上负责登录会不会好些呢？答案是不会，因为如果在这台机器上登录，但是接下来的会话又由其他节点来完成的话，浪费了之前花了很大成本导入到内存的cache信息。