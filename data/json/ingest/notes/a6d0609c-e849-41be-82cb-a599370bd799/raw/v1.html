---
title: 利用爬虫技术能做到哪些很酷很有趣很有用的事情？
updated: 2017-02-22 15:52:59Z
created: 2017-02-22 15:52:59Z
tags:
  - 知乎收藏
---



<en-note><p>爬图片，你懂的=。=，比如这个网站：<a HREF="http://link.zhihu.com/?target=http%3A//mm36d.com"><span>http://</span><span>mm36d.com</span><span></span><i></i></a></p><p>环境：</p><p>Python 2.7，request、BeautifulSoup三方库</p><p>见代码：</p><div><blockquote><code># -*- coding: utf8 -*-

import requests
from bs4 import BeautifulSoup
import os


def main():
    result_root_path = &apos;mm36d所有图片/&apos;  # 图片保存目录
    request_root_url = &apos;http://mm36d.com/belle/1/1/&apos;  # 根URL
    request_param_1 = 0  # 参数1
    total_image_count = 0  # 图片递增总数

    # 创建文件夹
    if not os.path.exists(result_root_path):
        os.makedirs(result_root_path)

    while True:
        request_param_1 += 1  # 参数1加1
        request_param_2 = 0  # 参数2

        # 请求头
        headers = {
            &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9.1) Gecko/20090624 Firefox/3.5 &apos;,
            &apos;Accept&apos;: &apos;text/plain&apos;,
            &apos;Connection&apos;: &apos;close&apos;
        }

        while True:
            request_param_2 += 1  # 参数2加1
            request_url = request_root_url + str(request_param_1) + &apos;/&apos; + str(request_param_2)  # 拼接URL

            print(&apos;Page: &apos; + request_url)

            requests.session().keep_alive = False

            try:
                # 获取页面内容
                response = requests.get(request_url, headers=headers, allow_redirects=False)

                # 请求成功
                if response.status_code == 200:
                    soup = BeautifulSoup(response.text, &apos;html.parser&apos;)  # BeautifulSoup解析
                    response.close()  # 关闭请求
                    image_url = soup.find(&apos;img&apos;, {&apos;class&apos;: &apos;lazy&apos;})[&apos;data-original&apos;]  # 提取图片URL

                    response = requests.get(image_url)  # 下载图片
                    image_file = open(result_root_path + str(total_image_count) + &apos;.jpg&apos;, &apos;wb&apos;)  # 创建图片文件
                    image_file.write(response.content)  # 写图片
                    image_file.close()  # 关闭文件
                    response.close()  # 关闭请求

                    total_image_count += 1  # 计数增加
                    print(image_url + &apos; done. Current: &apos; + str(total_image_count))
                else:
                    print(&apos;Next page&apos;)
                    break
            except Exception as e:
                print(&apos;Error: &apos; + e.__doc__)


if __name__ == &apos;__main__&apos;:
    main()
</code></blockquote></div><p>更多详情: <a HREF="http://www.zhihu.com/question/27621722/answer/146022005">http://www.zhihu.com/question/27621722/answer/146022005</a></p></en-note>      